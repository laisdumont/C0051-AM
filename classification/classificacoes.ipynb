{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados UFCA - Classe Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/dadosProntos.csv')\n",
    "\n",
    "# Separando os atributos das classes\n",
    "x = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1:].values.ravel()\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(5)\n",
    "\n",
    "fold_accuracy1 = []\n",
    "fold_matrix1 = []\n",
    "\n",
    "for train_index, test_index in folds.split(x, y):\n",
    "\n",
    "    clf1 = RandomForestClassifier( )\n",
    "    clf1.fit(x[train_index],y[train_index])\n",
    "    predicted1 = clf1.predict(x[test_index])\n",
    "    fold_matrix1.append(metrics.confusion_matrix(y[test_index],predicted1))\n",
    "    fold_accuracy1.append(metrics.accuracy_score(y[test_index],predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(5)\n",
    "\n",
    "fold_accuracy2 = []\n",
    "fold_matrix2 = []\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x = min_max_scaler.fit_transform(x)\n",
    "\n",
    "for train_index, test_index in folds.split(x, y):\n",
    "\n",
    "    clf2 = SVC()\n",
    "    clf2.fit(x[train_index],y[train_index])\n",
    "    predicted2 = clf2.predict(x[test_index])\n",
    "    fold_matrix2.append(metrics.confusion_matrix(y[test_index],predicted2))\n",
    "    fold_accuracy2.append(metrics.accuracy_score(y[test_index],predicted2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia e Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Random Forest')\n",
    "\n",
    "print('Acurácias:',fold_accuracy1)\n",
    "print('Média das acurácias:',np.mean(fold_accuracy1))\n",
    "print('Desvio padrão das acurácias:',np.std(fold_accuracy1))\n",
    "\n",
    "print('Matrizes de Confusão')\n",
    "for i in fold_matrix1:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sn.set(font_scale=1) # for label size\n",
    "    sn.heatmap(i, annot=True, fmt=\".1f\") # font size\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print('Support Vector Machine')\n",
    "\n",
    "print('Acurácias:',fold_accuracy2)\n",
    "print('Média das acurácias:',np.mean(fold_accuracy2))\n",
    "print('Desvio padrão das acurácias:',np.std(fold_accuracy2))\n",
    "\n",
    "print('Matrizes de Confusão') \n",
    "for i in fold_matrix2:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sn.set(font_scale=1) # for label size\n",
    "    sn.heatmap(i, annot=True, fmt=\".1f\") # font size\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes Estatísticos - Wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = SVC(kernel='rbf',cache_size=200,C=1,degree=3)\n",
    "model2 = RandomForestClassifier()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Extract results for each model on the same folds\n",
    "results_model1 = cross_val_score(model1, x, y, cv=kf)\n",
    "results_model2 = cross_val_score(model2, x, y, cv=kf)\n",
    "\n",
    "# Calculate p value\n",
    "stat, p = wilcoxon(results_model1, results_model2, zero_method='zsplit'); p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados UFCA - Clustering (2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/dadosCom2Classes.csv')\n",
    "\n",
    "# Separando os atributos das classes\n",
    "x_2classes = df.iloc[:,:-1].values\n",
    "y_2classes = df.iloc[:,-1:].values.ravel()\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_2classes = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(5)\n",
    "\n",
    "fold_accuracy1_2classes = []\n",
    "fold_matrix1_2classes = []\n",
    "\n",
    "for train_index, test_index in folds.split(x_2classes, y_2classes):\n",
    "\n",
    "    clf1 = RandomForestClassifier( )\n",
    "    clf1.fit(x_2classes[train_index],y_2classes[train_index])\n",
    "    predicted1 = clf1.predict(x_2classes[test_index])\n",
    "    fold_matrix1_2classes.append(metrics.confusion_matrix(y_2classes[test_index],predicted1))\n",
    "    fold_accuracy1_2classes.append(metrics.accuracy_score(y_2classes[test_index],predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(5)\n",
    "\n",
    "fold_accuracy2_2classes = []\n",
    "fold_matrix2_2classes = []\n",
    "\n",
    "for train_index, test_index in folds.split(x_2classes, y_2classes):\n",
    "\n",
    "    clf2 = SVC(kernel='rbf',cache_size=200,C=1,degree=3)\n",
    "    clf2.fit(x_2classes[train_index],y_2classes[train_index])\n",
    "    predicted2 = clf2.predict(x_2classes[test_index])\n",
    "    fold_matrix2_2classes.append(metrics.confusion_matrix(y_2classes[test_index],predicted2))\n",
    "    fold_accuracy2_2classes.append(metrics.accuracy_score(y_2classes[test_index],predicted2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia e Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Random Forest')\n",
    "\n",
    "print('Acurácias:',fold_accuracy1_2classes)\n",
    "print('Média das acurácias:',np.mean(fold_accuracy1_2classes))\n",
    "print('Desvio padrão das acurácias:',np.std(fold_accuracy1_2classes))\n",
    "\n",
    "print('Matrizes de Confusão')\n",
    "for i in fold_matrix1_2classes:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sn.set(font_scale=1) # for label size\n",
    "    sn.heatmap(i, annot=True, fmt=\".1f\") # font size\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print('Support Vector Machine')\n",
    "\n",
    "print('Acurácias:',fold_accuracy2_2classes)\n",
    "print('Média das acurácias:',np.mean(fold_accuracy2_2classes))\n",
    "print('Desvio padrão das acurácias:',np.std(fold_accuracy2_2classes))\n",
    "\n",
    "print('Matrizes de Confusão') \n",
    "for i in fold_matrix2_2classes:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sn.set(font_scale=1) # for label size\n",
    "    sn.heatmap(i, annot=True, fmt=\".1f\") # font size\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes Estatísticos - Wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_2classes = SVC(kernel='rbf',cache_size=200,C=1,degree=3)\n",
    "model2_2classes = RandomForestClassifier()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Extract results for each model on the same folds\n",
    "results_model1_2classes = cross_val_score(model1_2classes, x_2classes, y_2classes, cv=kf)\n",
    "results_model2_2classes = cross_val_score(model2_2classes, x_2classes, y_2classes, cv=kf)\n",
    "\n",
    "# Calculate p value\n",
    "stat, p = wilcoxon(results_model1_2classes, results_model2_2classes, zero_method='zsplit'); p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados UFCA - Clustering (3 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/dadosCom3Classes.csv')\n",
    "\n",
    "# Separando os atributos das classes\n",
    "x_3classes = df.iloc[:,:-1].values\n",
    "y_3classes = df.iloc[:,-1:].values.ravel()\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_3classes = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(5)\n",
    "\n",
    "fold_accuracy1_3classes = []\n",
    "fold_matrix1_3classes = []\n",
    "\n",
    "for train_index, test_index in folds.split(x, y_3classes):\n",
    "\n",
    "    clf1 = RandomForestClassifier( )\n",
    "    clf1.fit(x_3classes[train_index],y_3classes[train_index])\n",
    "    predicted1 = clf1.predict(x_3classes[test_index])\n",
    "    fold_matrix1_3classes.append(metrics.confusion_matrix(y_3classes[test_index],predicted1))\n",
    "    fold_accuracy1_3classes.append(metrics.accuracy_score(y_3classes[test_index],predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(5)\n",
    "\n",
    "fold_accuracy2_3classes = []\n",
    "fold_matrix2_3classes = []\n",
    "\n",
    "for train_index, test_index in folds.split(x_3classes, y_3classes):\n",
    "\n",
    "    clf2 = SVC(kernel='rbf',cache_size=200,C=1,degree=3)\n",
    "    clf2.fit(x_3classes[train_index],y_3classes[train_index])\n",
    "    predicted2 = clf2.predict(x_3classes[test_index])\n",
    "    fold_matrix2_3classes.append(metrics.confusion_matrix(y_3classes[test_index],predicted2))\n",
    "    fold_accuracy2_3classes.append(metrics.accuracy_score(y_3classes[test_index],predicted2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia e Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Random Forest')\n",
    "\n",
    "print('Acurácias:',fold_accuracy1_3classes)\n",
    "print('Média das acurácias:',np.mean(fold_accuracy1_3classes))\n",
    "print('Desvio padrão das acurácias:',np.std(fold_accuracy1_3classes))\n",
    "\n",
    "print('Matrizes de Confusão')\n",
    "for i in fold_matrix1_3classes:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sn.set(font_scale=1) # for label size\n",
    "    sn.heatmap(i, annot=True, fmt=\".1f\") # font size\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print('Support Vector Machine')\n",
    "\n",
    "print('Acurácias:',fold_accuracy2_3classes)\n",
    "print('Média das acurácias:',np.mean(fold_accuracy2_3classes))\n",
    "print('Desvio padrão das acurácias:',np.std(fold_accuracy2_3classes))\n",
    "\n",
    "print('Matrizes de Confusão') \n",
    "for i in fold_matrix2_3classes:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sn.set(font_scale=1) # for label size\n",
    "    sn.heatmap(i, annot=True, fmt=\".1f\") # font size\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes Estatísticos - Wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_3classes = SVC(kernel='rbf',cache_size=200,C=1,degree=3)\n",
    "model2_3classes = RandomForestClassifier()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Extract results for each model on the same folds\n",
    "results_model1_3classes = cross_val_score(model1_3classes, x_3classes, y_3classes, cv=kf)\n",
    "results_model2_3classes = cross_val_score(model2_3classes, x_3classes, y_3classes, cv=kf)\n",
    "\n",
    "# Calculate p value\n",
    "stat, p = wilcoxon(results_model1_3classes, results_model2_3classes, zero_method='zsplit'); p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados Externos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/dadosExternosTratados.csv')\n",
    "\n",
    "# Separando os atributos das classes\n",
    "x_externo = df.iloc[:,:-1].values\n",
    "y_externo = df.iloc[:,-1:].values.ravel()\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_externo = min_max_scaler.fit_transform(x_externo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(5)\n",
    "\n",
    "fold_accuracy1_externo = []\n",
    "fold_matrix1_externo = []\n",
    "\n",
    "accuracy_max = 0\n",
    "\n",
    "for train_index, test_index in folds.split(x_externo, y_externo):\n",
    "\n",
    "    clf1 = RandomForestClassifier( )\n",
    "    clf1.fit(x_externo[train_index],y_externo[train_index])\n",
    "    predicted1 = clf1.predict(x_externo[test_index])\n",
    "    fold_matrix1_externo.append(metrics.confusion_matrix(y_externo[test_index],predicted1))\n",
    "    fold_accuracy = metrics.accuracy_score(y_externo[test_index],predicted1)\n",
    "    fold_accuracy1_externo.append(fold_accuracy)\n",
    "\n",
    "    if fold_accuracy > accuracy_max:\n",
    "        clf_max_rfe = clf1\n",
    "        accuracy_max = fold_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(5)\n",
    "\n",
    "fold_accuracy2_externo = []\n",
    "fold_matrix2_externo = []\n",
    "\n",
    "for train_index, test_index in folds.split(x_externo, y_externo):\n",
    "\n",
    "    clf2 = SVC(kernel='rbf',cache_size=200,C=1,degree=3)\n",
    "    clf2.fit(x_externo[train_index],y_externo[train_index])\n",
    "    predicted2 = clf2.predict(x_externo[test_index])\n",
    "    fold_matrix2_externo.append(metrics.confusion_matrix(y_externo[test_index],predicted2))\n",
    "    fold_accuracy2_externo.append(metrics.accuracy_score(y_externo[test_index],predicted2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia e Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Random Forest')\n",
    "\n",
    "print('Acurácias:',fold_accuracy1_externo)\n",
    "print('Média das acurácias:',np.mean(fold_accuracy1_externo))\n",
    "print('Desvio padrão das acurácias:',np.std(fold_accuracy1_externo))\n",
    "\n",
    "print('Matrizes de Confusão')\n",
    "for i in fold_matrix1_externo:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sn.set(font_scale=1) # for label size\n",
    "    sn.heatmap(i, annot=True, fmt=\".1f\") # font size\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print('Support Vector Machine')\n",
    "\n",
    "print('Acurácias:',fold_accuracy2_externo)\n",
    "print('Média das acurácias:',np.mean(fold_accuracy2_externo))\n",
    "print('Desvio padrão das acurácias:',np.std(fold_accuracy2_externo))\n",
    "\n",
    "print('Matrizes de Confusão') \n",
    "for i in fold_matrix2_externo:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sn.set(font_scale=1) # for label size\n",
    "    sn.heatmap(i, annot=True, fmt=\".1f\") # font size\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes Estatísticos - Wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "model1_externo = SVC(kernel='rbf',cache_size=200,C=1,degree=3)\n",
    "model2_externo = RandomForestClassifier()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Extract results for each model on the same folds\n",
    "results_model1_externo = cross_val_score(model1_externo, x_externo, y_externo, cv=kf)\n",
    "results_model2_externo = cross_val_score(model2_externo, x_externo, y_externo, cv=kf)\n",
    "\n",
    "# Calculate p value\n",
    "stat, p = wilcoxon(results_model1_externo, results_model2_externo, zero_method='zsplit'); p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico do Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico da árvore com o melhor resultado\n",
    "plt.figure(figsize=(30,30))\n",
    "tree.plot_tree(clf_max_rfe.estimators_[0], feature_names=x[train_index], filled=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
